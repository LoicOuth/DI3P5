---
layout: Part
author: "Ruihau TETAHIO"
meta:
  - name: env
    content: dev,test,prod
---

# Horizontal Pod Autoscaling

Afin de supporter la charge et permettre aux diff√©rents d√©ploiements d'√™tre √©lastiques, de l'Horizontal Pod Autoscalind a √©t√© mis en place dans le projet.

## D√©finition

L'Horizontal Pod Autoscaling est un moyen de rendre les d√©ploiements applicatifs √©lastiques en rajoutant ou en supprimant des pods du d√©ploiement. Il met √† l'√©chelle ces derniers selon plusieurs crit√®res :

- Le % de ressources utilis√© par les pods d'un d√©ploiement
- Le nombre de r√©pliques minimum
- Le nombre de r√©pliques maximum

## Mise en place

### Pr√©requis

- Avoir install√© `metrics-server` sur le cluster Kubernetes

    **metrics-server** est le composant permettant de monitorer les ressources utilis√©es par les pods d'un cluster. Sans ce composant, le HPA ne peut pas fonctionner.

### Activation du HPA

Dans notre projet, la mise en place des HPA se fait automatiquement gr√¢ce aux templates Helm utilis√©s. Lors de la g√©n√©ration des templates par les d√©veloppeurs, un fichier `hpa.yaml` est automatiquement cr√©√© dans le dossier `üìÅ templates` de la chart.

Il suffit de rajouter les valeurs suivantes dans le fichier `values.yaml` :

```yaml
autoscaling:
  enabled: true
  minReplicas: 1
  maxReplicas: 4
  targetCPUUtilizationPercentage: 80
  targetMemoryUtilizationPercentage: 80
```

Les valeurs sont assez explicites et n'ont √† mon sens pas besoin d'√™tre expliqu√©es. Cependant, pour que les HPA jouent leurs r√¥les, il faut qu'ils aient une valeure sur laquelle se baser. Actuellement, aucune limite de consommation n'est donn√©e aux conteneurs du d√©ploiement. Pour cela, nous avons besoin de sp√©cifier les ressources √† alouer : les **requests** et les **limits**.

Encore une fois, les charts Helm √©tant bien faites, il suffit de rajouter les valeurs suivantes dans le fichier `values.yaml` pour activer les requests et les limites :

```yaml
resources:
  requests:
    memory: 256Mi
    cpu: 150m
  limits:
    memory: 512Mi
    cpu: 500m
```

Une fois ces modifications faites, le HPA est pr√™t √† remplir son r√¥le. On peut v√©rifier cela avec la commande `kubectl get hpa -A` :

```bash
$ kubectl get hpa -A
NAMESPACE    NAME                                                       REFERENCE                                                             TARGETS           MINPODS   MAXPODS   REPLICAS   AGE
usite-prod   backend-prod-usite-backend-service                         Deployment/backend-prod-usite-backend-service                         45%/80%, 2%/80%   1         4         1          77m
```

## Bugs connus

### Le HPA retourne des unknown

**Sympt√¥mes** : Lorsque la commande `kubectl get hpa -A`, le HPA me retourne des valeurs **unknown** :

```bash
$ kubectl get hpa -A
NAMESPACE    NAME                                                       REFERENCE                                                             TARGETS           MINPODS   MAXPODS   REPLICAS   AGE
usite-prod   frontend-presentation-prod-frontend-presentation-service   Deployment/frontend-presentation-prod-frontend-presentation-service   45%/80%, 6%/80%   1         4         2          77m
```

**Causes et solutions** :

1. Les ressources **requests** et **limits** n'ont pas √©t√© d√©finies

    Commencer par v√©rifier les logs.

    V√©rifier le d√©ploiement.  Dans la chart Helm, v√©rifier que la ligne suivante est bien renseign√©e :

    ```yaml
            resources:
                {{- toYaml .Values.resources | nindent 12 }}
    ```

    V√©rifier ensuite que les valeurs sont bien renseign√©es dans le fichier **values.yaml** (le fichier par d√©faut ou le fichier d'override) :

    ```yaml
    resources:
      requests:
        memory: 256Mi
        cpu: 150m
      limits:
        memory: 512Mi
        cpu: 500m
    ```

    V√©rifier que l'indentation est bien resp√©ct√©e (pas de tab) car le langage YAML est tr√®s sensible √† cela.

2. Les logs de mon HPA me retournent une erreur **unable to fetch metrics from resource metrics API: the server is currently unable to handle the request (get pods.metrics.k8s.io)**

    Ce message d'erreur veut dire que soit le pod metrics-server n'est pas encore pr√™t, soit qu'il y a un probl√®me avec le d√©ploiement.

    Dans le premier cas de figure, attendre quelques minutes. Les metrics devraient remonter.

    Si le probl√®me n'est toujours pas r√©solu, red√©ployer le d√©ploiement metrics-server.

## R√©f√©rences

- [Kubernetes Documentation - Horizontal Pod Autoscaling](https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/)
- [Kubernetes Documentation - HorizontalPodAutoscaler Walkthrough](https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/)
- [Github - kubernetes-sigs/metrics-server](https://github.com/kubernetes-sigs/metrics-server)
